#!/usr/bin/env python
"""
Write changepoint and classification information into JSON files.
"""

import argparse
import numpy
import os
import os.path
import rpy2
import rpy2.interactive.packages
import rpy2.robjects
import sys

from rpy2.rinterface import R_VERSION_BUILD

_REPO_ROOT = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
_LMREGRESSION_FILE = os.path.join(_REPO_ROOT, 'warmup', 'LMRegression.r')

sys.path.insert(0, _REPO_ROOT)
from warmup.krun_results import read_krun_results_file, write_krun_results_file


class Segment(object):
    """A single segment between two changepoints.
    """

    def __init__(self, start, end, mean, variance, data):
        self.start = start
        self.end = end
        self.mean = mean
        self.variance = variance
        self.median = numpy.median(data)
        self.ci = 3.0 * (numpy.percentile(data, 90.0) - numpy.percentile(data, 10.0))
        self.lower_ci = self.median - self.ci
        self.upper_ci = self.median + self.ci

    def overlaps_with(self, other):
        """Return True if the confidence interval of 'other' segment overlaps
        with this segment.
        """
        assert isinstance(other, Segment)
        if self.upper_ci < other.lower_ci or other.upper_ci < self.lower_ci:
            return False
        return True

    @property
    def n(self):
        return self.end - self.start


class Segments(object):
    """A list of Segments for a whole run sequence.
    """

    def __init__(self, length, steady_state, cpts, means, variances, data):
        self.length = length  # Length of original data (might be without outliers).
        assert self.length == len(data)
        self.data = data
        self.steady_state = steady_state
        self.segments = list()
        assert len(means) == len(variances) == len(cpts)
        if len(means) == 1:
            segment = Segment(0, self.length - 1, means[0], variances[0], data)
            self.segments.append(segment)
        else:
            for index in xrange(len(means)):
                segment = None
                if index == 0:
                    segment = Segment(0, cpts[index], means[index],
                                      variances[index], data[:cpts[index]])
                else:
                    segment = Segment(cpts[index - 1], cpts[index], means[index],
                                      variances[index], data[cpts[index - 1]:cpts[index]])
                self.segments.append(segment)
        assert cpts[:-1] == [s.end for s in self.segments][:-1]

    @property
    def means(self):
        return [segment.mean for segment in self.segments]

    @property
    def changepoints(self):
        """Return all changepoints.
        The last location in the data is always a changepoint, so we ignore it.
        """
        if len(self.segments) == 1:
            return list()
        return [segment.end for segment in self.segments][:-1]

    def get_classification(self):
        """Return the classification for this run sequence.
        """
        classification = ''
        # We do not use the first segment in the overlaps_with_last_segment
        # calculations. This is because in a classic warm-up execution, the
        # first segment will be short, and will a much larger mean than other
        # segments, and therefore any measure of variation will be very large .
        # If we include the first segment in the overlaps_with_last_segment
        # calculations, every warm-up execution will be classified as flat.
        overlaps_with_last_segment = list()
        for segment in self.segments[1:-1]:
            overlaps_with_last_segment.append(segment.overlaps_with(self.segments[-1]))
        if len(self.segments) == 1:
            classification = 'flat'
        # Slowdown -> last mean+ci does not overlap with another mean+ci and
        #             it is higher than the first mean+ci.
        elif self.segments[-1].mean == max(self.segments, key=lambda s: s.mean).mean:
            classification = 'slowdown'
        # Warmup -> last mean+ci does not overlap with another segment CI and
        #           is lower than the first mean+ci.
        elif (self.segments[-1].mean == min(self.segments, key=lambda s: s.mean).mean and
              self.segments[0].mean == max(self.segments, key=lambda s: s.mean).mean):
            classification = 'warmup'
        # Slow down -> not flat or a warm-up, and no changepoints after we
        #              expect a steady state.
        elif self.segments[-1].start < (self.length - self.steady_state):
            classification = 'slowdown'
        # No steady state -> there are changes after we expect steady state.
        elif self.segments[-1].start > (self.length - self.steady_state):
            classification = 'no steady state'
        else:
            raise ValueError('Could not classify data.')
        return classification


def main(in_files, steady_state):
    cpt = rpy2.interactive.packages.importr('changepoint')
    r_version = '.'.join(R_VERSION_BUILD[:2])
    print 'Using R version %s and changepoint library %s' % (r_version, cpt.__version__)
    assert cpt.__version__ >= '2.2.2', 'Please update the changepoint library.'
    assert r_version >= '3.3.1', 'Please update R from CRAN.'
    rpy2.robjects.r.source(_LMREGRESSION_FILE)
    cpt_reg = rpy2.robjects.globalenv['cpt.reg']  # Returns changepoints.
    krun_data = dict()
    for filename in in_files:
        assert os.path.exists(filename), 'File %s does not exist.' % filename
        print 'Loading: %s' % filename
        krun_data[filename] = read_krun_results_file(filename)
    for filename in krun_data:
        changepoints = dict()
        classifications = dict()
        changepoint_means = dict()
        rm_outliers = 'all_outliers' in krun_data[filename]
        if not rm_outliers:
            print ('No all_outliers key in %s; please run '
                   './bin/mark_outliers_in_json on your data if you want this '
                   'analysis to exclude outliers.'% filename)
        for bench in sorted(krun_data[filename]['wallclock_times']):
            changepoints[bench] = list()
            classifications[bench] = list()
            changepoint_means[bench] = list()
            for index, p_exec in enumerate(krun_data[filename]['wallclock_times'][bench]):
                if rm_outliers:
                    outliers = krun_data[filename]['all_outliers'][bench][index]
                else:
                    outliers = list()
                segments = get_segments(cpt_reg, p_exec, steady_state, outliers)
                changepoints[bench].append(segments.changepoints)
                changepoint_means[bench].append(segments.means)
                try:
                    classifications[bench].append(segments.get_classification())
                except ValueError:
                    print 'Could not classify %s execution %d' % (bench, index + 1)
                    sys.exit(1)
        krun_data[filename]['changepoints'] = changepoints
        krun_data[filename]['changepoint_means'] = changepoint_means
        krun_data[filename]['classifications'] = classifications
        krun_data[filename]['steady_state_expected'] = steady_state
        new_filename = create_output_filename(filename)
        print 'Writing out: %s' % new_filename
        write_krun_results_file(krun_data[filename], new_filename)


def get_segments(cpt_reg, data, steady_state, outliers):
    p_exec = data[:]  # data will be passed to Segments unchanged.
    length = len(p_exec)  # Will change when we remove outliers.
    indices = sorted(outliers, reverse=True)
    for index in indices:
        del p_exec[index]
    measurements = rpy2.robjects.FloatVector(p_exec)
    ones = rpy2.robjects.FloatVector([1.0 for _ in xrange(len(p_exec))])
    first_datum = 0.0  # TODO: Try other values here.
    rotated = rpy2.robjects.FloatVector([first_datum] + [t for t in p_exec[1:]])
    assert len(measurements) == len(ones) == len(rotated)
    matrix = rpy2.robjects.r.cbind(measurements, ones, rotated)
    changepoints = cpt_reg(matrix, method='PELT')
    # List indices in R start at 1.
    c_points = [int(cpoint - 1) for cpoint in changepoints.slots['cpts']]
    # Before we adjust the changepoints to account for any outliers that were
    # removed, we calculate the means and variances of each segment.
    means, variances = list(), list()
    for index, c_point in enumerate(c_points):
        if index == 0:
            start = 0
        else:
            start = c_points[index - 1]
        end = c_point
        segment_data = p_exec[start:end]
        print 'DATA:', p_exec, 'start,end:', (start, end), 'segment data:', segment_data
        means.append(numpy.mean(segment_data))
        variances.append(numpy.var(segment_data))
    # If outliers were deleted, the index of each changepoint will have moved.
    # Here, we adjust the indices to match the original data.
    for outlier in outliers:
        for index in xrange(len(c_points)):
            if c_points[index] >= outlier:
                c_points[index] += 1
    return Segments(length, steady_state, c_points, means, variances, data)


def create_output_filename(in_file_name):
    directory = os.path.dirname(in_file_name)
    basename = os.path.basename(in_file_name)
    if basename.endswith('.json.bz2'):
        root_name = basename[:-9]
    else:
        root_name = os.path.splitext(basename)[0]
    base_out = root_name + '_changepoints.json.bz2'
    return os.path.join(directory, base_out)


def create_cli_parser():
    """Create a parser to deal with command line switches.
    """
    script = os.path.basename(__file__)
    description = ("""Write changepoints and classifications into Krun results
file(s). If you want outliers to be excluded from the changepoint calculations,
you should first run your data through the ./bin/mark_outliers_in_json script.

This script does not alter your original Krun results file. Instead it writes
out a new file, with _changepoints added to the filename. For example if the
input file is:

    results_outliers_w200.json.bz2

the output of this script will be a new file named:

    results_outliers_w200_changepoints.json.bz2.

Example usage:
    $ python %s results1.json.bz2
    $ python %s  --steady 500 results1.json.bz2 results2.json.bz2\n""" % (script, script))
    parser = argparse.ArgumentParser(description)
    parser.add_argument('json_files', nargs='+', action='append', default=[],
                        type=str, help='One or more Krun result files.')
    parser.add_argument('--steady', '-s', action='store', dest='steady_state',
                        default=200, type=int, metavar='N',
                        help=('Expact a steady state should be reached before '
                              'the last N iterations.'))
    return parser


if __name__ == '__main__':
    parser = create_cli_parser()
    options = parser.parse_args()
    print ('Marking changepoints and classifications, expecting a steady state '
           'to be reached before the last %d iterations.' %
           options.steady_state)
    main(options.json_files[0], options.steady_state)
