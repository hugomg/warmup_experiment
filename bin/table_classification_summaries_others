#!/usr/bin/env python2.7
"""Summarise benchmark classifications.
Must be run after mark_changepoints_in_json.
"""

import argparse
import os
import os.path
import sys
import math

from collections import Counter

sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from warmup.krun_results import read_krun_results_file
from warmup.latex import STYLE_SYMBOLS, preamble, end_document, end_table, escape
from warmup.latex import get_latex_symbol_map, format_median_error
from warmup.statistics import bootstrap_confidence_interval


TITLE = 'Summary of benchmark classifications'
TABLE_FORMAT_START = 'l'
TABLE_FORMAT_PER_SPLIT = 'p{.5em}p{5pt}crrr'
TABLE_HEADINGS_START1 = '\\multicolumn{1}{c}{\\multirow{2}{*}{}}&'
TABLE_HEADINGS_START2 = '&'
TABLE_HEADINGS1 = '&&\\multicolumn{1}{c}{} &\\multicolumn{1}{c}{Steady}&\\multicolumn{1}{c}{Steady}&\\multicolumn{1}{c}{Steady}'
TABLE_HEADINGS2 = '&&\\multicolumn{1}{c}{Class.} &\\multicolumn{1}{c}{iter (\#)} &\\multicolumn{1}{c}{iter (s)}&\\multicolumn{1}{c}{perf (s)}'

BLANK_CELL = '\\begin{minipage}[c][\\blankheight]{0pt}\\end{minipage}'

SKIP_OUTER_KEYS = ['audit', 'reboots', 'window_size']

def main(data_dcts, window_size, latex_file, num_splits, with_preamble=False):
    # machine -> vm -> bench -> summary
    summary_data = dict()

    # although the user can pass >1 json file, there should never be two
    # different machines.
    assert len(data_dcts) == 1
    machine = data_dcts.keys()[0]

    all_benchs = set()
    keys = sorted(data_dcts[machine]['wallclock_times'].keys())
    for key in sorted(keys):
        wallclock_times = data_dcts[machine]['wallclock_times'][key]
        if len(wallclock_times) == 0:
            print ('WARNING: Skipping: %s from %s (no executions)' %
                   (key, machine))
        elif len(wallclock_times[0]) == 0:
            print('WARNING: Skipping: %s from %s (benchmark crashed)' %
                  (key, machine))
        else:
            bench, vm, variant = key.split(':')
            all_benchs |= set([bench])
            if vm not in summary_data:
                summary_data[vm] = {}
            if bench not in summary_data[vm]:
                summary_data[vm][bench] = {}

            # Get information for all p_execs of this key.
            categories = list()
            last_segment_means = list()
            last_changepoints = list()
            time_to_steadys = list()
            n_pexecs = len(data_dcts[machine]['wallclock_times'][key])
            for p_exec in xrange(n_pexecs):
                categories.append(data_dcts[machine]['classifications'][key][p_exec])
                last_segment_means.append(data_dcts[machine]['changepoint_means'][key][p_exec][-1])
                # Not all process execs have changepoints. However, all
                # p_execs will have one or more segment mean.
                if data_dcts[machine]['changepoints'][key][p_exec]:
                    last_changepoints.append(data_dcts[machine]['changepoints'][key][p_exec][-1])
                    to_steady = 0.0
                    for index in xrange(data_dcts[machine]['changepoints'][key][p_exec][-1]):
                        to_steady += data_dcts[machine]['wallclock_times'][key][p_exec][index]
                    time_to_steadys.append(to_steady)
                else:  # Flat execution, no changepoints.
                    time_to_steadys.append(0.0)
            # Average all information.
            category, occurences = Counter(categories).most_common()[0]
            if occurences == n_pexecs:
                reported_category = STYLE_SYMBOLS[category]
            else:
                reported_category = STYLE_SYMBOLS['inconsistent']
                cat_counts = list()
                for category, occurences in Counter(categories).most_common():
                    cat_counts.append('$%d$%s' % (occurences, STYLE_SYMBOLS[category]))
                reported_category += ' \\scriptsize(%s)' % ', '.join(cat_counts)

            if (reported_category == STYLE_SYMBOLS['no steady state'] or
                reported_category.startswith(STYLE_SYMBOLS['inconsistent'])):
                mean_last_segment = ''
                mean_last_cpt = ''
                time_to_steady = ''
            else:
                median, error = bootstrap_confidence_interval(last_segment_means)
                mean_last_segment = format_median_error(median, error)
                if last_changepoints:
                    median, error = bootstrap_confidence_interval(last_changepoints)
                    mean_last_cpt = format_median_error(median, error, as_integer=True)
                    median_t, error_t = bootstrap_confidence_interval(time_to_steadys)
                    time_to_steady = format_median_error(median_t, error_t, brief=True)
                else:  # No changepoints in any process executions.
                    mean_last_cpt = format_median_error(median, 0, as_integer=True)
                    time_to_steady = ''
            # Add summary for this benchmark.
            summary_data[vm][bench] = {'style': reported_category,
                'last_cpt': mean_last_cpt, 'last_mean': mean_last_segment,
                'time_to_steady_state':time_to_steady}
    # Write out results.
    write_results_as_latex(machine, list(sorted(all_benchs)), summary_data,
                           steady_state, latex_file, num_splits, with_preamble)


def write_results_as_latex(machine, all_benchs, summary, steady_state, tex_file,
                           num_splits, with_preamble=False):
    """Write a tex table to disk"""

    num_benchmarks = len(all_benchs)
    all_vms = sorted(summary.keys())
    num_vms = len(summary)

    # decide how to lay out the splits
    num_vms_rounded = \
        int(math.ceil(num_vms / float(num_splits)) * num_splits)
    vms_per_split = int(num_vms_rounded / float(num_splits))
    splits = [[] for x in xrange(num_splits)]
    vm_num = 0
    split_idx = 0
    for vm_idx in xrange(num_vms_rounded):
        try:
            vm = all_vms[vm_idx]
        except IndexError:
            vm = None  # no content in that cell
        splits[split_idx].append(vm)
        vm_num += 1
        if vm_num % vms_per_split == 0:
            split_idx += 1

    print('Writing data to %s.' % tex_file)
    with open(tex_file, 'w') as fp:
        if with_preamble:
            fp.write(preamble(TITLE))
            fp.write('%s' % get_latex_symbol_map())
            fp.write('\n\n\n')
        # emit table header
        heads1 = TABLE_HEADINGS_START1 + '&'.join([TABLE_HEADINGS1] * num_splits)
        heads2 = TABLE_HEADINGS_START2 + '&'.join([TABLE_HEADINGS2] * num_splits)
        heads = '%s\\\\%s' % (heads1, heads2)
        fmt = TABLE_FORMAT_START + TABLE_FORMAT_PER_SPLIT * num_splits
        fp.write(\
"""
{
\\begin{tabular}{%s}
\\toprule
%s \\\\
\\midrule
""" % (fmt, heads))

        split_row_idx = 0
        for row_vms in zip(*splits):
            bench_idx = 0
            for bench in sorted(all_benchs):
                row = []
                for vm in row_vms:
                    if vm is None:
                        continue # no more results
                    try:
                        this_summary = summary[vm][bench]
                    except KeyError:
                        last_cpt = BLANK_CELL
                        time_steady = BLANK_CELL
                        last_mean = BLANK_CELL
                        classification = ''
                    else:
                        classification = this_summary['style']
                        last_cpt = this_summary['last_cpt']
                        time_steady = this_summary['time_to_steady_state']
                        last_mean = this_summary['last_mean']

                        if 'inconsistent' in classification:
                            classification = '\\multicolumn{4}{l}{%s}' % classification
                        else:
                            classification = '\\multicolumn{1}{l}{%s}' % classification
                            if 'flatc' in classification:
                                last_cpt = BLANK_CELL
                                time_steady = BLANK_CELL
                    if last_cpt == '':
                        last_cpt = BLANK_CELL
                    if time_steady == '':
                        time_steady = BLANK_CELL
                    if last_mean == '':
                        last_mean = BLANK_CELL

                    if bench_idx == 0:
                        if num_benchmarks == 10:
                            fudge = 4
                        elif num_benchmarks == 12:
                            fudge = 5
                        else:
                            fudge = 0
                        vm_cell = '\\multirow{%s}{*}{\\rotatebox[origin=c]{90}{%s}}' \
                            % (num_benchmarks + fudge, vm)
                    else:
                        vm_cell = ''
                    if 'inconsistent' in classification:
                        row_add = [BLANK_CELL, vm_cell, classification]
                    else:
                        row_add = [BLANK_CELL, vm_cell, classification, last_cpt,
                                   time_steady, last_mean]
                    if not row:  # first bench in this row, needs the vm column
                        row.insert(0, escape(bench))
                    row.extend(row_add)
                    vm_idx += 1
                fp.write('&'.join(row))
                # Only -ve space row if not next to a midrule
                if bench_idx < num_vms - 1:
                    fp.write('\\\\[-3pt] \n')
                else:
                    fp.write('\\\\ \n')
                bench_idx += 1
            if split_row_idx < vms_per_split - 1:
                fp.write('\midrule\n')
            split_row_idx += 1
        fp.write(end_table())
        if with_preamble:
            fp.write(end_document())
    return


def get_data_dictionaries(json_files):
    """Read a list of BZipped JSON files and return their contents as a
    dictionaries of machine name -> JSON values.
    """
    data_dictionary = dict()
    steady_state = None
    for filename in json_files:
        assert os.path.exists(filename), 'File %s does not exist.' % filename
        print 'Loading: %s' % filename
        data = read_krun_results_file(filename)
        if 'classifications' not in data:
            print 'Please run mark_changepoints_in_json before re-running this script.'
            sys.exit(1)
        machine_name = data['audit']['uname'].split(' ')[1]
        if '.' in machine_name:  # Remove domain, if there is one.
            machine_name = machine_name.split('.')[0]
        if machine_name not in data_dictionary:
            data_dictionary[machine_name] = data
        else:  # We may have two datasets from the same machine.
            for outer_key in data:
                if outer_key in SKIP_OUTER_KEYS:
                    continue
                elif outer_key == 'steady_state_expected':
                    assert data_dictionary[machine_name][outer_key] == data[outer_key]
                    continue
                for key in data[outer_key]:
                    assert key not in data_dictionary[machine_name][outer_key]
                    if key not in data_dictionary[machine_name][outer_key]:
                        data_dictionary[machine_name][outer_key][key] = dict()
                    data_dictionary[machine_name][outer_key][key] = data[outer_key][key]
        if steady_state is None:
            steady_state = data['steady_state_expected']
        else:
            assert steady_state == data['steady_state_expected'], \
                   ('Cannot summarise categories generated with different' +
                    ' steady-state-expected values.')
    return steady_state, data_dictionary


def create_cli_parser():
    """Create a parser to deal with command line switches.
    """
    script = os.path.basename(__file__)
    description = (('Summarise benchmark classifications stored within a Krun ' +
                    'results file. Must be run after mark_changepoints_in_json.' +
                    '\n\nExample usage:\n\n' +
                    '\t$ python %s -l summary.tex results.json.bz2') % script)
    parser = argparse.ArgumentParser(description=description,
                                     formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('json_files', action='append', nargs='+', default=[],
                        type=str, help='One or more Krun result files.')
    parser.add_argument('--outfile', '-o', action='store', dest='latex_file',
                        type=str, help='Name of the LaTeX file to write to.',
                        required=True)
    parser.add_argument('--num_splits', '-s', action='store',
                        type=int, help='Number of horizontal splits.',
                        default=1)
    parser.add_argument('--with-preamble', action='store_true',
                        dest='with_preamble', default=False,
                        help='Write out a whole LaTeX article (not just the table).')
    return parser


if __name__ == '__main__':
    parser = create_cli_parser()
    options = parser.parse_args()
    steady_state, data_dcts = get_data_dictionaries(options.json_files[0])
    if options.with_preamble:
        print 'Writing out full document, with preamble.'
    main(data_dcts, steady_state, options.latex_file, options.num_splits,
         options.with_preamble)

