#!/usr/bin/env python2.7
"""Summarise benchmark classifications.
Must be run after mark_changepoints_in_json.
"""

import argparse
import os
import os.path
import sys
import math

from collections import Counter

sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from warmup.krun_results import read_krun_results_file
from warmup.latex import STYLE_SYMBOLS, preamble, end_document, end_table
from warmup.latex import format_median_error, get_latex_symbol_map
from warmup.statistics import bootstrap_confidence_interval


SKIP_OUTER_KEYS = ['audit', 'reboots', 'window_size', 'mperf_counts', 'aperf_counts',
                   'eta_estimates', 'starting_temperatures', 'core_cycle_counts',
                   'config', 'error_flag']

VM_NAMES_MAP = {
    'JRubyTruffle': 'JRuby+Truffle',
    'Hotspot': 'HotSpot'
}

BENCHMARK_NAMES_MAP = {
    'binarytrees': '\\binarytrees',
    'nbody': '\\nbody',
    'fannkuch_redux': '\\fannkuch',
    'richards': '\\richards',
    'fasta': '\\fasta',
    'spectralnorm': '\\spectralnorm',
}

TITLE = 'Summary of benchmark classifications'
TABLE_FORMAT = 'll@{\hspace{0cm}}lp{5pt}r@{\hspace{0cm}}r@{\hspace{0cm}}r@{\hspace{0cm}}l@{\hspace{.3cm}}lp{5pt}r@{\hspace{0cm}}r@{\hspace{0cm}}r'
TABLE_HEADINGS_START1 = '\\multicolumn{1}{c}{\\multirow{2}{*}{}}&'
TABLE_HEADINGS_START2 = '&'
TABLE_HEADINGS1 = '&&\\multicolumn{1}{c}{} &\\multicolumn{1}{c}{Steady}&\\multicolumn{1}{c}{Steady}&\\multicolumn{1}{c}{Steady}'
TABLE_HEADINGS2 = '&&\\multicolumn{1}{c}{Class.} &\\multicolumn{1}{c}{iter (\#)} &\\multicolumn{1}{c}{iter (s)}&\\multicolumn{1}{c}{perf (s)}'

BLANK_CELL = '\\begin{minipage}[c][\\blankheight]{0pt}\\end{minipage}'

def main(data_dcts, half_bound, delta, steady_state, latex_file, with_preamble=False):
    # machine -> vm -> bench -> summary
    summary_data = dict()

    # although the user can pass >1 json file, there should never be two
    # different machines.
    assert len(data_dcts) == 1
    machine = data_dcts.keys()[0]

    all_benchs = set()
    keys = sorted(data_dcts[machine]['wallclock_times'].keys())
    for key in sorted(keys):
        wallclock_times = data_dcts[machine]['wallclock_times'][key]
        if len(wallclock_times) == 0:
            print ('WARNING: Skipping: %s from %s (no executions)' %
                   (key, machine))
        elif len(wallclock_times[0]) == 0:
            print('WARNING: Skipping: %s from %s (benchmark crashed)' %
                  (key, machine))
        else:
            bench, vm, variant = key.split(':')
            all_benchs |= set([bench])
            if vm not in summary_data:
                summary_data[vm] = {}
            if bench not in summary_data[vm]:
                summary_data[vm][bench] = {}

            # Get information for all p_execs of this key.
            categories = list()
            steady_state_means = list()
            steady_iters = list()
            time_to_steadys = list()
            n_pexecs = len(data_dcts[machine]['wallclock_times'][key])
            for p_exec in xrange(n_pexecs):
                categories.append(data_dcts[machine]['classifications'][key][p_exec])
                # Next we calculate the iteration at which a steady state was
                # reached, it's average segment mean and the time to reach a
                # steady state. However, the last segment may be equivalent to
                # its adjacent segments, so we first need to know which segments
                # are steady-state segments.
                first_steady_segment = len(data_dcts[machine]['changepoint_means'][key][p_exec]) - 1
                num_steady_segments = 1
                last_segment_mean = data_dcts[machine]['changepoint_means'][key][p_exec][-1]
                lower_bound = min(last_segment_mean * (1.0 - half_bound), last_segment_mean - delta)
                upper_bound = max(last_segment_mean * (1.0 + half_bound), last_segment_mean + delta)
                for index in xrange(len(data_dcts[machine]['changepoint_means'][key][p_exec]) - 2, -1, -1):
                    current_segment_mean = data_dcts[machine]['changepoint_means'][key][p_exec][index]
                    if current_segment_mean >= lower_bound and current_segment_mean <= upper_bound:
                        first_steady_segment -= 1
                        num_steady_segments += 1
                    else:
                        break
                steady_state_mean = (math.fsum(data_dcts[machine]['changepoint_means'][key][p_exec][first_steady_segment:])
                                     / float(num_steady_segments))
                steady_state_means.append(steady_state_mean)
                # Not all process execs have changepoints. However, all
                # p_execs will have one or more segment mean.
                if data_dcts[machine]['changepoints'][key][p_exec]:
                    steady_iter = data_dcts[machine]['changepoints'][key][p_exec][first_steady_segment - 1]
                    steady_iters.append(steady_iter)
                    to_steady = 0.0
                    for index in xrange(steady_iter):
                        to_steady += data_dcts[machine]['wallclock_times'][key][p_exec][index]
                    time_to_steadys.append(to_steady)
                else:  # Flat execution, no changepoints.
                    time_to_steadys.append(0.0)
            # Average all information.
            if len(set(categories)) == 1 and len(categories) == n_pexecs:
                reported_category = STYLE_SYMBOLS[categories[0]]
            elif len(set(categories)) == 1:
                # Consistent benchmark, but some process execs failed with error.
                reported_category = ' %s\\scriptsize{($%d$)}' % \
                                    (STYLE_SYMBOLS[categories[0]], len(categories))
            elif set(categories) == set(['flat', 'warmup']):
                reported_category = STYLE_SYMBOLS['good inconsistent']
                cat_counts = list()
                for category, occurences in Counter(categories).most_common():
                    cat_counts.append('$%d$%s' % (occurences, STYLE_SYMBOLS[category]))
                reported_category += ' \\scriptsize(%s)' % ', '.join(cat_counts)
            else:  # Bad inconsistent.
                reported_category = STYLE_SYMBOLS['bad inconsistent']
                cat_counts = list()
                for category, occurences in Counter(categories).most_common():
                    cat_counts.append('$%d$%s' % (occurences, STYLE_SYMBOLS[category]))
                reported_category += ' \\scriptsize(%s)' % ', '.join(cat_counts)

            if STYLE_SYMBOLS['no steady state'] in reported_category:
                mean_steady = ''
                mean_steady_iter = ''
                time_to_steady = ''
            else:
                median_s, error_s = bootstrap_confidence_interval(steady_state_means)
                mean_steady = format_median_error(median_s, error_s)
                if steady_iters:
                    median_iter, error_iter = bootstrap_confidence_interval(steady_iters)
                    mean_steady_iter = format_median_error(median_iter, error_iter, as_integer=True)
                    median_t, error_t = bootstrap_confidence_interval(time_to_steadys)
                    time_to_steady = format_median_error(median_t, error_t, brief=True)
                else:  # No changepoints in any process executions.
                    mean_steady_iter = format_median_error(0, 0, as_integer=True)
                    time_to_steady = ''
            # Add summary for this benchmark.
            summary_data[vm][bench] = {'style': reported_category,
                'last_cpt': mean_steady_iter, 'last_mean': mean_steady,
                'time_to_steady_state':time_to_steady}
    # Write out results.
    write_results_as_latex(machine, list(sorted(all_benchs)), summary_data,
                           steady_state, latex_file, with_preamble)


def write_results_as_latex(machine, all_benchs, summary, steady_state, tex_file,
                           with_preamble=False):
    """Write a tex table to disk"""
    num_splits = 2  # 2 sets of VMs in each table

    num_benchmarks = len(all_benchs)
    num_vms = len(summary)

    # decide how to lay out the splits
    num_benchs_rounded = \
        int(math.ceil(num_benchmarks / float(num_splits)) * num_splits)
    benchs_per_split = int(num_benchs_rounded / float(num_splits))
    splits = [[] for x in xrange(num_splits)]
    bench_num = 0
    split_idx = 0
    for bench_idx in xrange(num_benchs_rounded):
        try:
            bench = all_benchs[bench_idx]
        except IndexError:
            bench = None  # no content in that cell
        splits[split_idx].append(bench)
        bench_num += 1
        if bench_num % benchs_per_split == 0:
            split_idx += 1

    print('Writing data to %s.' % tex_file)
    with open(tex_file, 'w') as fp:
        if with_preamble:
            fp.write(preamble(TITLE))
            fp.write('\centering %s' % get_latex_symbol_map())
            fp.write('\n\n\n')
            fp.write('\\begin{table*}[t]\n')
            fp.write('\\centering\n')
        # emit table header
        heads1 = TABLE_HEADINGS_START1 + '&'.join([TABLE_HEADINGS1] * num_splits)
        heads2 = TABLE_HEADINGS_START2 + '&'.join([TABLE_HEADINGS2] * num_splits)
        heads = '%s\\\\%s' % (heads1, heads2)
        fp.write(\
"""
{
\\begin{tabular}{%s}
\\toprule
%s \\\\
\\midrule
""" % (TABLE_FORMAT, heads))

        split_row_idx = 0
        for row_benchs in zip(*splits):
            vm_idx = 0
            for vm in sorted(summary.keys()):
                row = []
                for bench in row_benchs:
                    if bench is None:
                        continue # no more results
                    try:
                        this_summary = summary[vm][bench]
                    except KeyError:
                        last_cpt = BLANK_CELL
                        time_steady = BLANK_CELL
                        last_mean = BLANK_CELL
                        classification = ''
                    else:
                        classification = this_summary['style']
                        last_cpt = this_summary['last_cpt']
                        time_steady = this_summary['time_to_steady_state']
                        last_mean = this_summary['last_mean']

                        classification = '\\multicolumn{1}{l}{%s}' % classification
                        if classification == STYLE_SYMBOLS['flat']:
                            last_cpt = BLANK_CELL
                            time_steady = BLANK_CELL
                    if last_cpt == '':
                        last_cpt = BLANK_CELL
                    if time_steady == '':
                        time_steady = BLANK_CELL
                    if last_mean == '':
                        last_mean = BLANK_CELL

                    if vm_idx == 0:
                        if num_vms == 8:
                            fudge = 2
                        elif num_vms == 5:
                            fudge = 1
                        else:
                            fudge = 0
                        try:
                            bench_cell = '\\multirow{%s}{*}{\\rotatebox[origin=c]{90}{%s}}' \
                                % (num_vms + fudge, BENCHMARK_NAMES_MAP[bench])
                        except KeyError:
                            bench_cell = '\\multirow{%s}{*}{\\rotatebox[origin=c]{90}{%s}}' \
                                % (num_vms + fudge, bench)
                    else:
                        bench_cell = ''
                    row_add = [BLANK_CELL, bench_cell, classification, last_cpt,
                               time_steady, last_mean]
                    if not row:  # first vm in this row, needs the vm column
                        if VM_NAMES_MAP.has_key(vm):
                            row.insert(0, VM_NAMES_MAP[vm])
                        else:
                            row.insert(0, vm)
                    row.extend(row_add)
                    bench_idx += 1
                fp.write('&'.join(row))
                # Only -ve space row if not next to a midrule
                if vm_idx < num_vms - 1:
                    fp.write('\\\\[-3pt] \n')
                else:
                    fp.write('\\\\ \n')
                vm_idx += 1
            if split_row_idx < benchs_per_split - 1:
                fp.write('\midrule\n')
            split_row_idx += 1
        fp.write(end_table())
        if with_preamble:
            fp.write('\\end{table*}\n')
            fp.write(end_document())
    return


def get_data_dictionaries(json_files):
    """Read a list of BZipped JSON files and return their contents as a
    dictionaries of machine name -> JSON values.
    """
    data_dictionary = dict()
    classifier = None  # steady, delta, half_bound values used by classifer.
    for filename in json_files:
        assert os.path.exists(filename), 'File %s does not exist.' % filename
        print 'Loading: %s' % filename
        data = read_krun_results_file(filename)
        if 'classifications' not in data:
            print 'Please run mark_changepoints_in_json before re-running this script.'
            sys.exit(1)
        machine_name = data['audit']['uname'].split(' ')[1]
        if '.' in machine_name:  # Remove domain, if there is one.
            machine_name = machine_name.split('.')[0]
        if machine_name not in data_dictionary:
            data_dictionary[machine_name] = data
        else:  # We may have two datasets from the same machine.
            for outer_key in data:
                if outer_key in SKIP_OUTER_KEYS:
                    continue
                elif outer_key == 'classifier':
                    assert data_dictionary[machine_name][outer_key] == data[outer_key]
                    continue
                for key in data[outer_key]:
                    assert key not in data_dictionary[machine_name][outer_key]
                    if key not in data_dictionary[machine_name][outer_key]:
                        data_dictionary[machine_name][outer_key][key] = dict()
                    data_dictionary[machine_name][outer_key][key] = data[outer_key][key]
        if classifier is None:
            classifier = data['classifier']
        else:
            assert classifier == data['classifier'], \
                   ('Cannot summarise categories generated with different '
                    'command-line options for steady-state-expected, half_bound '
                    'or delta. Please re-run the mark_changepoints_in_json script.')
    return classifier, data_dictionary


def create_cli_parser():
    """Create a parser to deal with command line switches.
    """
    script = os.path.basename(__file__)
    description = (('Summarise benchmark classifications stored within a Krun ' +
                    'results file. Must be run after mark_changepoints_in_json.' +
                    '\n\nExample usage:\n\n' +
                    '\t$ python %s -l summary.tex results.json.bz2') % script)
    parser = argparse.ArgumentParser(description=description,
                                     formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument('json_files', action='append', nargs='+', default=[],
                        type=str, help='One or more Krun result files.')
    parser.add_argument('--outfile', '-o', action='store', dest='latex_file',
                        type=str, help='Name of the LaTeX file to write to.',
                        required=True)
    parser.add_argument('--with-preamble', action='store_true',
                        dest='with_preamble', default=False,
                        help='Write out a whole LaTeX article (not just the table).')
    return parser


if __name__ == '__main__':
    parser = create_cli_parser()
    options = parser.parse_args()
    classifier, data_dcts = get_data_dictionaries(options.json_files[0])
    if options.with_preamble:
        print 'Writing out full document, with preamble.'
    main(data_dcts, classifier['half_bound'], classifier['delta'], classifier['steady'],
         options.latex_file, options.with_preamble)
